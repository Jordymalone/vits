# VITS æƒ…ç·’æ§åˆ¶ç³»çµ±æ¶æ§‹åœ–ï¼ˆè«–æ–‡ç”¨ï¼‰

## ç³»çµ±ç¸½è¦½

æœ¬æ–‡æª”æä¾›å®Œæ•´çš„ VITS æƒ…ç·’æ§åˆ¶ç³»çµ±æ¶æ§‹æµç¨‹åœ–ï¼Œé©ç”¨æ–¼è«–æ–‡æ’°å¯«ã€‚

---

## 1. æ•´é«”ç³»çµ±æ¶æ§‹

```mermaid
flowchart TB
    subgraph Input["ğŸ“¥ è¼¸å…¥å±¤"]
        A1[æ–‡æœ¬åºåˆ—<br/>Text Sequence]
        A2[èªªè©±è€… ID<br/>Speaker ID]
        A3[æƒ…ç·’ ID<br/>Emotion ID]
        A4[åƒè€ƒéŸ³é »<br/>Reference Audio<br/>å¯é¸]
    end

    subgraph Embedding["ğŸ”¤ åµŒå…¥å±¤"]
        B1[æ–‡æœ¬ç·¨ç¢¼<br/>Text Encoder]
        B2[èªªè©±è€…åµŒå…¥<br/>Speaker Embedding<br/>gin_channels=256]
        B3[æƒ…ç·’åµŒå…¥<br/>Emotion Embedding<br/>n_emotions=4]
        B4[eGeMAPS æå–å™¨<br/>eGeMAPS Extractor<br/>å¯é¸]
    end

    subgraph Fusion["ğŸ”€ ç‰¹å¾µèåˆ"]
        C1[å‘é‡ç›¸åŠ <br/>g = g_speaker + g_emotion]
        C2[eGeMAPS ç·¨ç¢¼å™¨<br/>Encoder 88â†’192 dims<br/>å¯é¸]
    end

    subgraph TextEnc["ğŸ“ æ–‡æœ¬ç·¨ç¢¼å™¨"]
        D1[Transformer Encoder<br/>6 Layers]
        D2[Conditional LayerNorm<br/>CLN]
        D3[Cross Conditional Attention<br/>CCA å¯é¸]
    end

    subgraph Duration["â±ï¸ æŒçºŒæ™‚é–“é æ¸¬"]
        E1[Stochastic Duration<br/>Predictor SDP]
        E2[Deterministic Duration<br/>Predictor DP]
        E3[æ··åˆé æ¸¬<br/>0.1Ã—SDP + 0.9Ã—DP]
    end

    subgraph Posterior["ğŸµ å¾Œé©—ç·¨ç¢¼å™¨"]
        F1[Posterior Encoder<br/>Mel â†’ Latent z_q]
        F2[æ¢ä»¶è¼¸å…¥<br/>g speaker+emotion]
    end

    subgraph Flow["ğŸŒŠ æ­£è¦åŒ–æµ"]
        G1[Residual Coupling Blocks<br/>with CLN]
        G2[å‰å‘: z_q â†’ z_p<br/>åå‘: z_p â†’ z_q]
    end

    subgraph Decoder["ğŸ”Š è§£ç¢¼å™¨"]
        H1[HiFi-GAN Decoder<br/>with CLN]
        H2[æ¢ä»¶è¼¸å…¥<br/>g speaker+emotion]
    end

    subgraph Output["ğŸ“¤ è¼¸å‡ºå±¤"]
        I1[åˆæˆæ³¢å½¢<br/>Waveform]
        I2[æ³¨æ„åŠ›å°é½Š<br/>Attention Alignment]
    end

    A1 --> B1
    A2 --> B2
    A3 --> B3
    A4 -.å¯é¸.-> B4

    B2 --> C1
    B3 --> C1
    B4 -.å¯é¸.-> C2

    B1 --> D1
    C1 --> D2
    C2 -.å¯é¸.-> D3
    D1 --> D2
    D2 --> D3
    D3 --> E1
    D3 --> E2

    E1 --> E3
    E2 --> E3

    E3 --> F1
    C1 --> F2
    F2 --> F1

    F1 --> G1
    C1 --> G1
    G1 --> G2

    G2 --> H1
    C1 --> H2
    H2 --> H1

    H1 --> I1
    D3 --> I2

    style Input fill:#e1f5ff
    style Embedding fill:#fff4e1
    style Fusion fill:#ffe1f5
    style TextEnc fill:#e1ffe1
    style Duration fill:#f5e1ff
    style Posterior fill:#ffe1e1
    style Flow fill:#e1e1ff
    style Decoder fill:#ffffe1
    style Output fill:#e1ffff
```

---

## 2. è¨“ç·´æµç¨‹ (Training Pipeline)

```mermaid
flowchart TB
    subgraph Data["ğŸ“‚ æ•¸æ“šè¼‰å…¥"]
        D1[(Filelist<br/>audio|sid|lang|text|eid)]
        D2[TextAudioSpeakerLoader]
        D3[Batch Collate]
    end

    subgraph Input["ğŸ“¥ è¨“ç·´è¼¸å…¥"]
        I1[æ–‡æœ¬ x]
        I2[Mel é »è­œ y]
        I3[èªªè©±è€… ID sid]
        I4[æƒ…ç·’ ID eid]
    end

    subgraph Forward["âš¡ å‰å‘å‚³æ’­"]
        F1[SynthesizerTrn.forward]
        F2[æ–‡æœ¬ç·¨ç¢¼ + CLN/CCA]
        F3[æŒçºŒæ™‚é–“é æ¸¬ + CLN]
        F4[Posterior ç·¨ç¢¼]
        F5[Flow æ­£è¦åŒ–]
        F6[HiFi-GAN è§£ç¢¼]
    end

    subgraph Loss["ğŸ“‰ æå¤±è¨ˆç®—"]
        L1[Duration Loss<br/>L_dur]
        L2[Mel Loss<br/>L_mel]
        L3[KL Divergence<br/>L_kl]
        L4[Adversarial Loss<br/>L_adv]
        L5[Feature Matching<br/>L_fm]
        L6[ç¸½æå¤±<br/>L_total]
    end

    subgraph Optimize["ğŸ”„ å„ªåŒ–"]
        O1[Generator å„ªåŒ–å™¨]
        O2[Discriminator å„ªåŒ–å™¨]
        O3[æ›´æ–°åƒæ•¸]
    end

    D1 --> D2
    D2 --> D3
    D3 --> I1 & I2 & I3 & I4

    I1 & I2 & I3 & I4 --> F1
    F1 --> F2 --> F3 --> F4 --> F5 --> F6

    F3 --> L1
    F6 --> L2
    F5 --> L3
    F6 --> L4 & L5

    L1 & L2 & L3 & L4 & L5 --> L6

    L6 --> O1 & O2
    O1 & O2 --> O3
    O3 -.è¿­ä»£.-> F1

    style Data fill:#e1f5ff
    style Input fill:#fff4e1
    style Forward fill:#e1ffe1
    style Loss fill:#ffe1e1
    style Optimize fill:#f5e1ff
```

---

## 3. æ¨è«–æµç¨‹ (Inference Pipeline)

```mermaid
flowchart TB
    subgraph UserInput["ğŸ‘¤ ç”¨æˆ¶è¼¸å…¥"]
        U1[æ–‡æœ¬<br/>Text]
        U2[èªªè©±è€… ID<br/>Speaker ID]
        U3[æƒ…ç·’ ID<br/>Emotion ID]
        U4[åƒè€ƒéŸ³é »<br/>Reference Audio<br/>å¯é¸]
    end

    subgraph Preprocess["ğŸ”§ é è™•ç†"]
        P1[æ–‡æœ¬ â†’ éŸ³ç´ åºåˆ—]
        P2[æ’å…¥ç©ºç™½ç¬¦]
        P3[è½‰æ›ç‚º Tensor]
    end

    subgraph Embed["ğŸ”¤ åµŒå…¥"]
        E1[èªªè©±è€…åµŒå…¥<br/>emb_g sid]
        E2[æƒ…ç·’åµŒå…¥<br/>emb_e eid]
        E3[å‘é‡èåˆ<br/>g = g_s + g_e]
        E4[eGeMAPS æå–<br/>å¯é¸]
    end

    subgraph Encode["ğŸ“ ç·¨ç¢¼"]
        EN1[Text Encoder<br/>with CLN]
        EN2[CCA æ³¨å…¥<br/>å¯é¸]
        EN3[è¼¸å‡ºå‡å€¼ m_p<br/>å’Œæ–¹å·® logs_p]
    end

    subgraph Predict["â±ï¸ é æ¸¬æŒçºŒæ™‚é–“"]
        PR1[SDP + DP æ··åˆ]
        PR2[ç”Ÿæˆå°é½Šè·¯å¾‘<br/>Monotonic Alignment]
        PR3[ä¸Šæ¡æ¨£åˆ°éŸ³é »å¹€]
    end

    subgraph Sample["ğŸ² æ¡æ¨£"]
        S1[å¾ N m_p, logs_p<br/>æ¡æ¨£ z_p]
        S2[Flow åå‘<br/>z_p â†’ z]
    end

    subgraph Decode["ğŸ”Š è§£ç¢¼"]
        DE1[HiFi-GAN Decoder<br/>with g condition]
        DE2[ç”Ÿæˆæ³¢å½¢]
    end

    subgraph Output["ğŸ“¤ è¼¸å‡º"]
        O1[åˆæˆèªéŸ³<br/>Audio Waveform]
        O2[æ³¨æ„åŠ›åœ–<br/>Attention Map]
    end

    U1 --> P1
    P1 --> P2
    P2 --> P3

    U2 --> E1
    U3 --> E2
    U4 -.å¯é¸.-> E4
    E1 & E2 --> E3

    P3 & E3 --> EN1
    E4 -.å¯é¸.-> EN2
    EN1 --> EN2
    EN2 --> EN3

    EN3 --> PR1
    E3 --> PR1
    PR1 --> PR2
    PR2 --> PR3

    EN3 --> S1
    PR3 --> S1
    S1 --> S2
    E3 --> S2

    S2 --> DE1
    E3 --> DE1
    DE1 --> DE2

    DE2 --> O1
    PR2 --> O2

    style UserInput fill:#e1f5ff
    style Preprocess fill:#fff4e1
    style Embed fill:#ffe1f5
    style Encode fill:#e1ffe1
    style Predict fill:#f5e1ff
    style Sample fill:#e1e1ff
    style Decode fill:#ffffe1
    style Output fill:#e1ffff
```

---

## 4. æƒ…ç·’æ§åˆ¶æ©Ÿåˆ¶è©³è§£

```mermaid
flowchart TB
    subgraph EmotionInput["ğŸ­ æƒ…ç·’è¼¸å…¥"]
        EI1[é›¢æ•£æƒ…ç·’ ID<br/>eid âˆˆ 0,1,2,3]
        EI2[é€£çºŒè²å­¸ç‰¹å¾µ<br/>eGeMAPS å¯é¸]
    end

    subgraph EmotionEmbed["ğŸ”¢ æƒ…ç·’è¡¨ç¤º"]
        EE1[Emotion Embedding<br/>eid â†’ R^256]
        EE2[eGeMAPS Encoder<br/>R^88 â†’ R^192]
    end

    subgraph Condition["ğŸ¯ æ¢ä»¶æ³¨å…¥"]
        C1[Conditional LayerNorm<br/>CLN]
        C2[Cross Conditional<br/>Attention CCA]
    end

    subgraph CLN_Detail["ğŸ“ CLN æ©Ÿåˆ¶"]
        CL1[æ¨™æº–åŒ–<br/>x_norm = x - Î¼ / Ïƒ]
        CL2[æ¢ä»¶èª¿è£½<br/>Î³_c, Î²_c = f g]
        CL3[è¼¸å‡º<br/>y = x_norm Ã— 1+Î³_c + Î²_c]
    end

    subgraph CCA_Detail["ğŸ”— CCA æ©Ÿåˆ¶"]
        CA1[Query ä¾†è‡ªæ–‡æœ¬<br/>Q = W_q Ã— x_text]
        CA2[Key, Value ä¾†è‡ªæƒ…ç·’<br/>K,V = W_k,v Ã— emo_feat]
        CA3[æ³¨æ„åŠ›è¨ˆç®—<br/>Attn Q,K Ã— V]
        CA4[æ®˜å·®é€£æ¥<br/>x + Attn]
    end

    subgraph Impact["ğŸ’« æƒ…ç·’å½±éŸ¿"]
        IM1[æŒçºŒæ™‚é–“<br/>Duration]
        IM2[éŸ³é«˜éŸ»å¾‹<br/>Pitch/F0]
        IM3[èƒ½é‡éŸ¿åº¦<br/>Energy]
        IM4[é »è­œç‰¹å¾µ<br/>Spectral]
    end

    EI1 --> EE1
    EI2 -.å¯é¸.-> EE2

    EE1 --> C1
    EE2 -.å¯é¸.-> C2

    C1 --> CL1
    CL1 --> CL2
    CL2 --> CL3

    C2 --> CA1
    C2 --> CA2
    CA2 --> CA3
    CA1 --> CA3
    CA3 --> CA4

    CL3 --> IM1 & IM2 & IM3 & IM4
    CA4 --> IM1 & IM2 & IM3 & IM4

    style EmotionInput fill:#ffe1f5
    style EmotionEmbed fill:#fff4e1
    style Condition fill:#e1ffe1
    style CLN_Detail fill:#e1f5ff
    style CCA_Detail fill:#f5e1ff
    style Impact fill:#ffffe1
```

---

## 5. æ¢ä»¶å±¤æ­¸ä¸€åŒ– (CLN) è©³ç´°æµç¨‹

```mermaid
flowchart LR
    subgraph Input["è¼¸å…¥"]
        I1[ç‰¹å¾µ x<br/>B,C,T]
        I2[æ¢ä»¶ g<br/>B,gin_ch,1]
    end

    subgraph Norm["æ¨™æº–åŒ–"]
        N1[è¨ˆç®—å‡å€¼ Î¼]
        N2[è¨ˆç®—æ–¹å·® ÏƒÂ²]
        N3[x_norm =<br/>x - Î¼ / âˆš ÏƒÂ² + Îµ]
    end

    subgraph Condition["æ¢ä»¶ç”Ÿæˆ"]
        C1[Conv1D<br/>gin_ch â†’ 2Ã—C]
        C2[åˆ†å‰²ç‚º<br/>Î³_c å’Œ Î²_c]
    end

    subgraph Modulate["æ¢ä»¶èª¿è£½"]
        M1[ç¸®æ”¾<br/>x_norm Ã— 1 + Î³_c]
        M2[å¹³ç§»<br/>+ Î²_c]
    end

    subgraph Output["è¼¸å‡º"]
        O1[èª¿è£½å¾Œç‰¹å¾µ<br/>y B,C,T]
    end

    I1 --> N1 & N2
    N1 & N2 --> N3

    I2 --> C1
    C1 --> C2

    N3 --> M1
    C2 --> M1
    M1 --> M2
    C2 --> M2

    M2 --> O1

    style Input fill:#e1f5ff
    style Norm fill:#fff4e1
    style Condition fill:#ffe1f5
    style Modulate fill:#e1ffe1
    style Output fill:#ffffe1
```

**æ•¸å­¸å…¬å¼**:

$$
\begin{align}
\text{CLN}(x, g) &= \gamma_c \odot \text{LN}(x) + \beta_c \\
[\gamma_c, \beta_c] &= \text{Conv1D}(g) \\
\text{LN}(x) &= \frac{x - \mu}{\sqrt{\sigma^2 + \epsilon}} \odot \gamma + \beta
\end{align}
$$

---

## 6. äº¤å‰æ¢ä»¶æ³¨æ„åŠ› (CCA) è©³ç´°æµç¨‹

```mermaid
flowchart TB
    subgraph Input["ğŸ“¥ è¼¸å…¥"]
        I1[æ–‡æœ¬ç‰¹å¾µ<br/>x_text B,C,T_text]
        I2[æƒ…ç·’ç‰¹å¾µ<br/>emo_feat B,C_emo,T_emo]
    end

    subgraph Projection["ğŸ”€ æŠ•å½±"]
        P1[Query æŠ•å½±<br/>Q = Conv_q x_text<br/>B,C,T_text]
        P2[Key æŠ•å½±<br/>K = Conv_k emo_feat<br/>B,C,T_emo]
        P3[Value æŠ•å½±<br/>V = Conv_v emo_feat<br/>B,C,T_emo]
    end

    subgraph MultiHead["ğŸ”¢ å¤šé ­åˆ†å‰²"]
        M1[Q â†’ Q_1,...,Q_h<br/>h=4 heads]
        M2[K â†’ K_1,...,K_h]
        M3[V â†’ V_1,...,V_h]
    end

    subgraph Attention["âš¡ æ³¨æ„åŠ›è¨ˆç®—"]
        A1[å°æ¯å€‹é ­ i:<br/>Attn_i = softmax Q_i K_i^T / âˆšd_k]
        A2[Out_i = Attn_i Ã— V_i]
        A3[æ‹¼æ¥æ‰€æœ‰é ­<br/>Out = Concat Out_1,...,Out_h]
    end

    subgraph Output["ğŸ“¤ è¼¸å‡º"]
        O1[è¼¸å‡ºæŠ•å½±<br/>y = Conv_o Out]
        O2[æ®˜å·®é€£æ¥<br/>x_text + y]
        O3[LayerNorm<br/>LN x_text + y]
    end

    I1 --> P1
    I2 --> P2 & P3

    P1 --> M1
    P2 --> M2
    P3 --> M3

    M1 & M2 --> A1
    A1 --> A2
    M3 --> A2
    A2 --> A3

    A3 --> O1
    O1 --> O2
    I1 --> O2
    O2 --> O3

    style Input fill:#e1f5ff
    style Projection fill:#fff4e1
    style MultiHead fill:#ffe1f5
    style Attention fill:#e1ffe1
    style Output fill:#ffffe1
```

**æ•¸å­¸å…¬å¼**:

$$
\begin{align}
\text{CCA}(x, c) &= \text{LN}(x + \text{MultiHead}(Q, K, V)) \\
Q &= W_q x, \quad K = W_k c, \quad V = W_v c \\
\text{MultiHead}(Q,K,V) &= \text{Concat}(\text{head}_1, ..., \text{head}_h)W_o \\
\text{head}_i &= \text{Attention}(QW_i^Q, KW_i^K, VW_i^V) \\
\text{Attention}(Q,K,V) &= \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
\end{align}
$$

---

## 7. æŒçºŒæ™‚é–“é æ¸¬æ©Ÿåˆ¶

```mermaid
flowchart TB
    subgraph Input["ğŸ“¥ è¼¸å…¥"]
        I1[æ–‡æœ¬ç·¨ç¢¼<br/>x B,C,T]
        I2[æ¢ä»¶å‘é‡<br/>g B,gin_ch,1]
    end

    subgraph SDP["ğŸ² éš¨æ©Ÿé æ¸¬å™¨ (SDP)"]
        S1[Transformer Encoder<br/>with CLN]
        S2[Projection<br/>C â†’ 1]
        S3[Flow Matching<br/>å­¸ç¿’åˆ†å¸ƒ]
        S4[è¼¸å‡º log_dur_sdp]
    end

    subgraph DP["ğŸ“ ç¢ºå®šæ€§é æ¸¬å™¨ (DP)"]
        D1[Conv Blocks<br/>with CLN]
        D2[ReLU + Dropout]
        D3[Projection<br/>C â†’ 1]
        D4[è¼¸å‡º log_dur_dp]
    end

    subgraph Combine["ğŸ”€ æ··åˆç­–ç•¥"]
        C1[è¨“ç·´æ™‚:<br/>log_dur = log_dur_gt<br/>ç”¨æ–¼å°é½Š]
        C2[æ¨è«–æ™‚:<br/>log_dur = 0.1Ã—sdp + 0.9Ã—dp]
        C3[exp log_dur<br/>ç²å¾—æŒçºŒæ™‚é–“]
    end

    subgraph Alignment["ğŸ¯ å°é½Šç”Ÿæˆ"]
        A1[Monotonic Alignment<br/>Search MAS]
        A2[ç”Ÿæˆå°é½Šè·¯å¾‘<br/>attn T_text,T_audio]
        A3[ä¸Šæ¡æ¨£æ–‡æœ¬ç‰¹å¾µ<br/>x_expanded]
    end

    I1 & I2 --> S1
    S1 --> S2
    S2 --> S3
    S3 --> S4

    I1 & I2 --> D1
    D1 --> D2
    D2 --> D3
    D3 --> D4

    S4 --> C1
    D4 --> C1
    C1 --> C2
    C2 --> C3

    C3 --> A1
    I1 --> A1
    A1 --> A2
    A2 --> A3

    style Input fill:#e1f5ff
    style SDP fill:#ffe1f5
    style DP fill:#fff4e1
    style Combine fill:#e1ffe1
    style Alignment fill:#ffffe1
```

**æƒ…ç·’å°æŒçºŒæ™‚é–“çš„å½±éŸ¿**:
- **Happy**: æŒçºŒæ™‚é–“ â†“ (èªé€Ÿå¿«)
- **Sad**: æŒçºŒæ™‚é–“ â†‘ (èªé€Ÿæ…¢)
- **Angry**: æŒçºŒæ™‚é–“ â†“ (èªé€Ÿå¿«ã€æ€¥ä¿ƒ)
- **Neutral**: åŸºæº–æŒçºŒæ™‚é–“

---

## 8. æ•¸æ“šæµç¨‹

```mermaid
flowchart TB
    subgraph Raw["ğŸ“‚ åŸå§‹æ•¸æ“š"]
        R1[éŸ³é »æª”æ¡ˆ<br/>*.wav]
        R2[æ–‡æœ¬æ¨™è¨»<br/>*.txt]
        R3[æƒ…ç·’æ¨™ç±¤<br/>metadata]
    end

    subgraph Prepare["ğŸ”§ æ•¸æ“šæº–å‚™"]
        P1[éŸ³ç´ åŒ–<br/>G2P]
        P2[æƒ…ç·’æ˜ å°„<br/>Label â†’ ID]
        P3[ç”Ÿæˆ Filelist<br/>prepare_emotion_filelist.py]
    end

    subgraph Filelist["ğŸ“‹ Filelist"]
        F1[æ ¼å¼:<br/>path|sid|lang|phonemes|eid]
        F2[è¨“ç·´é›†<br/>emotion_train.txt]
        F3[é©—è­‰é›†<br/>emotion_val.txt]
    end

    subgraph Loader["ğŸ“¥ æ•¸æ“šè¼‰å…¥"]
        L1[TextAudioSpeakerLoader]
        L2[è®€å–éŸ³é »]
        L3[è¨ˆç®— Mel é »è­œ]
        L4[æ–‡æœ¬ç·¨ç¢¼]
    end

    subgraph Batch["ğŸ“¦ Batch è™•ç†"]
        B1[BucketSampler<br/>ç›¸ä¼¼é•·åº¦åˆ†çµ„]
        B2[TextAudioSpeakerCollate<br/>å¡«å……å°é½Š]
        B3[è¼¸å‡º Batch<br/>x,spec,wav,sid,eid]
    end

    subgraph Training["ğŸ“ è¨“ç·´"]
        T1[é€å…¥æ¨¡å‹<br/>SynthesizerTrn]
    end

    R1 & R2 & R3 --> P1
    P1 --> P2
    P2 --> P3

    P3 --> F1
    F1 --> F2 & F3

    F2 & F3 --> L1
    L1 --> L2 & L3 & L4

    L2 & L3 & L4 --> B1
    B1 --> B2
    B2 --> B3

    B3 --> T1

    style Raw fill:#e1f5ff
    style Prepare fill:#fff4e1
    style Filelist fill:#ffe1f5
    style Loader fill:#e1ffe1
    style Batch fill:#f5e1ff
    style Training fill:#ffffe1
```

---

## 9. æ¨¡å‹çµ„ä»¶å±¤æ¬¡çµæ§‹

```mermaid
flowchart TB
    subgraph Model["ğŸ¯ SynthesizerTrn"]
        direction TB

        subgraph Encoders["ç·¨ç¢¼å™¨"]
            E1[TextEncoder<br/>enc_p]
            E2[PosteriorEncoder<br/>enc_q]
        end

        subgraph Predictors["é æ¸¬å™¨"]
            P1[DurationPredictor<br/>dp]
            P2[StochasticDP<br/>sdp]
        end

        subgraph Transform["è½‰æ›å™¨"]
            T1[ResidualCouplingBlock<br/>flow]
        end

        subgraph Generator["ç”Ÿæˆå™¨"]
            G1[HiFi-GAN Decoder<br/>dec]
        end

        subgraph Embeddings["åµŒå…¥å±¤"]
            EM1[Speaker Embedding<br/>emb_g]
            EM2[Emotion Embedding<br/>emb_e]
        end

        subgraph Optional["å¯é¸æ¨¡çµ„"]
            O1[eGeMAPS Extractor<br/>egemaps_extractor]
            O2[eGeMAPS Encoder<br/>egemaps_encoder]
        end
    end

    Encoders -.ä½¿ç”¨.-> Embeddings
    Predictors -.ä½¿ç”¨.-> Embeddings
    Transform -.ä½¿ç”¨.-> Embeddings
    Generator -.ä½¿ç”¨.-> Embeddings

    Encoders -.å¯é¸ä½¿ç”¨.-> Optional

    style Model fill:#e1f5ff
    style Encoders fill:#fff4e1
    style Predictors fill:#ffe1f5
    style Transform fill:#e1ffe1
    style Generator fill:#f5e1ff
    style Embeddings fill:#ffffe1
    style Optional fill:#e1e1ff
```

---

## 10. æƒ…ç·’ç‰¹å¾µæå– (eGeMAPS - å¯é¸)

```mermaid
flowchart TB
    subgraph Input["ğŸ“¥ åƒè€ƒéŸ³é »"]
        I1[æ³¢å½¢<br/>Waveform B,T_wav]
    end

    subgraph Extract["ğŸ”Š ç‰¹å¾µæå–"]
        E1[MFCC<br/>13 ç¶­]
        E2[Mel-spectrogram<br/>80 ç¶­]
        E3[F0 åŸºé »<br/>1 ç¶­]
        E4[Energy èƒ½é‡<br/>1 ç¶­]
        E5[Spectral Flux<br/>1 ç¶­]
        E6[Zero Crossing Rate<br/>1 ç¶­]
    end

    subgraph Concat["ğŸ”— ç‰¹å¾µæ‹¼æ¥"]
        C1[ç¸½ç‰¹å¾µå‘é‡<br/>97 ç¶­]
        C2[MLP æŠ•å½±<br/>97 â†’ 88 ç¶­]
    end

    subgraph Encode["ğŸ“Š ç·¨ç¢¼"]
        EN1[Conv1D Encoder<br/>3 å±¤]
        EN2[LayerNorm + ReLU]
        EN3[è¼¸å‡º<br/>B,192,T_feat]
    end

    subgraph Usage["ğŸ¯ ä½¿ç”¨æ–¹å¼"]
        U1[è¼¸å…¥åˆ° CCA<br/>ä½œç‚ºæ¢ä»¶ç‰¹å¾µ]
        U2[èˆ‡æ–‡æœ¬ç‰¹å¾µ<br/>äº¤å‰æ³¨æ„åŠ›]
    end

    I1 --> E1 & E2 & E3 & E4 & E5 & E6
    E1 & E2 & E3 & E4 & E5 & E6 --> C1
    C1 --> C2

    C2 --> EN1
    EN1 --> EN2
    EN2 --> EN3

    EN3 --> U1
    U1 --> U2

    style Input fill:#e1f5ff
    style Extract fill:#fff4e1
    style Concat fill:#ffe1f5
    style Encode fill:#e1ffe1
    style Usage fill:#ffffe1
```

**æ³¨æ„**: æœ¬å¯¦ä½œä½¿ç”¨ç´” Label IDï¼ŒeGeMAPS ç‚ºå¯é¸å¢å¼·åŠŸèƒ½ã€‚

---

## 11. æå¤±å‡½æ•¸æ¶æ§‹

```mermaid
flowchart TB
    subgraph Losses["ğŸ’° æå¤±å‡½æ•¸"]
        direction TB

        subgraph Generator["ğŸ¨ ç”Ÿæˆå™¨æå¤±"]
            G1[Duration Loss<br/>L_dur = MSE dur_pred, dur_gt]
            G2[Mel Loss<br/>L_mel = L1 mel_pred, mel_gt]
            G3[KL Divergence<br/>L_kl = KL z_p || z_q]
            G4[Adversarial Loss<br/>L_adv_g = -E log D y_fake]
            G5[Feature Matching<br/>L_fm = Î£ ||f_real - f_fake||]
        end

        subgraph Discriminator["ğŸ” åˆ¤åˆ¥å™¨æå¤±"]
            D1[Real Loss<br/>L_real = -E log D y_real]
            D2[Fake Loss<br/>L_fake = -E log 1-D y_fake]
            D3[Total D Loss<br/>L_d = L_real + L_fake]
        end

        subgraph Total["ğŸ“Š ç¸½æå¤±"]
            T1[Generator Total<br/>L_g = L_dur + c_melÃ—L_mel +<br/>c_klÃ—L_kl + L_adv + L_fm]
            T2[æ¬Šé‡<br/>c_mel=45, c_kl=1.0]
        end
    end

    G1 & G2 & G3 & G4 & G5 --> T1
    T2 -.é…ç½®.-> T1

    style Losses fill:#e1f5ff
    style Generator fill:#e1ffe1
    style Discriminator fill:#ffe1e1
    style Total fill:#ffffe1
```

**æå¤±å‡½æ•¸æ•¸å­¸è¡¨é”**:

$$
\begin{align}
\mathcal{L}_{\text{dur}} &= \text{MSE}(\log d_{\text{pred}}, \log d_{\text{gt}}) \\
\mathcal{L}_{\text{mel}} &= ||M_{\text{pred}} - M_{\text{gt}}||_1 \\
\mathcal{L}_{\text{kl}} &= \text{KL}(q(z|x) || p(z)) \\
\mathcal{L}_{\text{adv}} &= -\mathbb{E}[\log D(G(z))] \\
\mathcal{L}_{\text{fm}} &= \sum_{i=1}^{T} \frac{1}{N_i}||D^i(y) - D^i(\hat{y})||_1 \\
\mathcal{L}_{\text{G}} &= \mathcal{L}_{\text{dur}} + c_{\text{mel}}\mathcal{L}_{\text{mel}} + c_{\text{kl}}\mathcal{L}_{\text{kl}} + \mathcal{L}_{\text{adv}} + \mathcal{L}_{\text{fm}}
\end{align}
$$

---

## 12. è©•ä¼°èˆ‡æ¸¬è©¦æµç¨‹

```mermaid
flowchart TB
    subgraph Test["ğŸ§ª æ¸¬è©¦è¨­ç½®"]
        T1[è¼‰å…¥æ¨¡å‹<br/>Checkpoint]
        T2[è¨­å®šæ¸¬è©¦æ–‡æœ¬<br/>Test Text]
        T3[è¨­å®šåƒæ•¸<br/>speaker, emotions]
    end

    subgraph Generate["ğŸµ ç”Ÿæˆå¤šç¨®æƒ…ç·’"]
        G1[Neutral ID=0]
        G2[Happy ID=1]
        G3[Sad ID=2]
        G4[Angry ID=3]
    end

    subgraph Analyze["ğŸ“Š å®¢è§€åˆ†æ"]
        A1[æŒçºŒæ™‚é–“<br/>Duration]
        A2[èƒ½é‡<br/>RMS Energy]
        A3[åŸºé »<br/>F0 Estimation]
        A4[æœ€å¤§æŒ¯å¹…<br/>Max Amplitude]
    end

    subgraph Compare["ğŸ“ˆ å°æ¯”åˆ†æ"]
        C1[è¨ˆç®—ç›¸å°å·®ç•°<br/>vs Neutral %]
        C2[ç”Ÿæˆçµ±è¨ˆè¡¨æ ¼]
        C3[è¼¸å‡º JSON å ±å‘Š]
    end

    subgraph Subjective["ğŸ‘‚ ä¸»è§€è©•ä¼°"]
        S1[è½è¦ºæ¸¬è©¦<br/>Listening Test]
        S2[æƒ…ç·’å¯è¾¨è­˜åº¦<br/>Emotion Recognition]
        S3[è‡ªç„¶åº¦è©•åˆ†<br/>Naturalness MOS]
    end

    T1 & T2 & T3 --> G1 & G2 & G3 & G4

    G1 & G2 & G3 & G4 --> A1 & A2 & A3 & A4

    A1 & A2 & A3 & A4 --> C1
    C1 --> C2
    C2 --> C3

    G1 & G2 & G3 & G4 --> S1
    S1 --> S2 & S3

    style Test fill:#e1f5ff
    style Generate fill:#fff4e1
    style Analyze fill:#e1ffe1
    style Compare fill:#ffe1f5
    style Subjective fill:#ffffe1
```

---

## 13. å®Œæ•´ç³»çµ±è³‡è¨Šæµ

```mermaid
flowchart LR
    subgraph Stage1["éšæ®µ 1: è¼¸å…¥"]
        S1A[æ–‡æœ¬]
        S1B[èªªè©±è€…]
        S1C[æƒ…ç·’]
    end

    subgraph Stage2["éšæ®µ 2: åµŒå…¥"]
        S2A[æ–‡æœ¬ç·¨ç¢¼]
        S2B[èªªè©±è€…å‘é‡]
        S2C[æƒ…ç·’å‘é‡]
    end

    subgraph Stage3["éšæ®µ 3: æ¢ä»¶èåˆ"]
        S3A[g = g_s + g_e]
        S3B[CLN èª¿è£½]
        S3C[CCA æ³¨å…¥]
    end

    subgraph Stage4["éšæ®µ 4: ç·¨ç¢¼"]
        S4A[æ–‡æœ¬ â†’ éš±å‘é‡]
        S4B[æŒçºŒæ™‚é–“é æ¸¬]
        S4C[å°é½Šç”Ÿæˆ]
    end

    subgraph Stage5["éšæ®µ 5: ç”Ÿæˆ"]
        S5A[Flow æ¡æ¨£]
        S5B[HiFi-GAN è§£ç¢¼]
    end

    subgraph Stage6["éšæ®µ 6: è¼¸å‡º"]
        S6A[èªéŸ³æ³¢å½¢]
    end

    S1A --> S2A
    S1B --> S2B
    S1C --> S2C

    S2B & S2C --> S3A
    S3A --> S3B & S3C

    S2A & S3B & S3C --> S4A
    S4A --> S4B
    S4B --> S4C

    S4C & S3A --> S5A
    S5A & S3A --> S5B

    S5B --> S6A

    style Stage1 fill:#e1f5ff
    style Stage2 fill:#fff4e1
    style Stage3 fill:#ffe1f5
    style Stage4 fill:#e1ffe1
    style Stage5 fill:#f5e1ff
    style Stage6 fill:#ffffe1
```

---

## 14. ä»£ç¢¼æ¶æ§‹å°æ‡‰

### æ ¸å¿ƒæ–‡ä»¶æ˜ å°„

```mermaid
flowchart TB
    subgraph Code["ğŸ’» ä»£ç¢¼æ¶æ§‹"]
        direction LR

        subgraph Core["æ ¸å¿ƒæ¨¡å‹"]
            C1[models.py<br/>SynthesizerTrn]
            C2[modules.py<br/>CLN, Layers]
            C3[attentions.py<br/>CCA, Attention]
        end

        subgraph Emotion["æƒ…ç·’çµ„ä»¶"]
            E1[Emotion Embedding<br/>models.py:509-510]
            E2[eGeMAPS Extractor<br/>egemaps_extractor.py]
            E3[eGeMAPS Encoder<br/>egemaps_extractor.py]
        end

        subgraph Data["æ•¸æ“šè™•ç†"]
            D1[data_utils.py<br/>Loader + Collate]
            D2[text/<br/>Text Processing]
            D3[mel_processing.py<br/>Mel Computation]
        end

        subgraph Train["è¨“ç·´èˆ‡æ¨è«–"]
            T1[train_ms.py<br/>Training Loop]
            T2[infer.py<br/>Inference]
            T3[losses.py<br/>Loss Functions]
        end

        subgraph Utils["è¼”åŠ©å·¥å…·"]
            U1[prepare_emotion_filelist.py<br/>Data Preparation]
            U2[test_emotion_control.py<br/>Testing]
        end
    end

    C1 -.uses.-> C2 & C3
    C1 -.contains.-> E1
    C1 -.optional.-> E2 & E3
    T1 -.uses.-> C1 & D1
    T2 -.uses.-> C1 & D2

    style Code fill:#e1f5ff
    style Core fill:#e1ffe1
    style Emotion fill:#ffe1f5
    style Data fill:#fff4e1
    style Train fill:#f5e1ff
    style Utils fill:#ffffe1
```

### é—œéµé¡åˆ¥èˆ‡æ–¹æ³•

| çµ„ä»¶ | æ–‡ä»¶ä½ç½® | é—œéµæ–¹æ³• |
|------|---------|---------|
| **SynthesizerTrn** | models.py:415-825 | `forward()`, `infer()` |
| **TextEncoder** | models.py:133-196 | `forward()` with CCA |
| **DurationPredictor** | models.py:80-130 | `forward()` with CLN |
| **ConditionalLayerNorm** | modules.py:34-75 | `forward()` |
| **CrossConditionalAttention** | attentions.py:257-345 | `forward()` |
| **eGeMAPS_Extractor** | egemaps_extractor.py:20-150 | `extract_*()`, `forward()` |
| **TextAudioSpeakerLoader** | data_utils.py:160-287 | `__getitem__()`, `_filter()` |

---

## 15. è«–æ–‡åœ–è¡¨å»ºè­°

### å»ºè­°çš„è«–æ–‡åœ–è¡¨é †åº

1. **ç³»çµ±ç¸½è¦½åœ–** (åœ– 1)
   - ä½¿ç”¨ã€Œæ•´é«”ç³»çµ±æ¶æ§‹ã€æµç¨‹åœ–
   - å±•ç¤ºå®Œæ•´çš„è¼¸å…¥åˆ°è¼¸å‡ºæµç¨‹

2. **æƒ…ç·’æ§åˆ¶æ©Ÿåˆ¶** (åœ– 2)
   - ä½¿ç”¨ã€Œæƒ…ç·’æ§åˆ¶æ©Ÿåˆ¶è©³è§£ã€
   - é‡é»æ¨™è¨» CLN å’Œ CCA

3. **CLN æ¶æ§‹** (åœ– 3)
   - ä½¿ç”¨ã€Œæ¢ä»¶å±¤æ­¸ä¸€åŒ–è©³ç´°æµç¨‹ã€
   - é…åˆæ•¸å­¸å…¬å¼

4. **CCA æ¶æ§‹** (åœ– 4)
   - ä½¿ç”¨ã€Œäº¤å‰æ¢ä»¶æ³¨æ„åŠ›è©³ç´°æµç¨‹ã€
   - å±•ç¤ºå¤šé ­æ³¨æ„åŠ›æ©Ÿåˆ¶

5. **è¨“ç·´æµç¨‹** (åœ– 5)
   - ä½¿ç”¨ã€Œè¨“ç·´æµç¨‹ã€
   - æ¨™è¨»æå¤±å‡½æ•¸

6. **æ¨è«–æµç¨‹** (åœ– 6)
   - ä½¿ç”¨ã€Œæ¨è«–æµç¨‹ã€
   - å±•ç¤ºç”¨æˆ¶å¦‚ä½•æ§åˆ¶æƒ…ç·’

7. **å¯¦é©—çµæœ** (è¡¨æ ¼)
   - å®¢è§€æŒ‡æ¨™å°æ¯”è¡¨
   - ä¸»è§€è©•ä¼° MOS è¡¨

### LaTeX åœ–è¡¨å¼•ç”¨ç¯„ä¾‹

```latex
\begin{figure}[htbp]
\centering
\includegraphics[width=\linewidth]{emotion_control_architecture.pdf}
\caption{VITS æƒ…ç·’æ§åˆ¶ç³»çµ±æ•´é«”æ¶æ§‹ã€‚ç³»çµ±æ¥æ”¶æ–‡æœ¬ã€èªªè©±è€… ID å’Œæƒ…ç·’ ID ä½œç‚ºè¼¸å…¥ï¼Œé€šé Conditional LayerNorm (CLN) å’Œ Cross Conditional Attention (CCA) æ©Ÿåˆ¶å°‡æƒ…ç·’ä¿¡æ¯æ³¨å…¥åˆ°æ¨¡å‹å„å±¤ï¼Œæœ€çµ‚ç”Ÿæˆå…·æœ‰æŒ‡å®šæƒ…ç·’çš„èªéŸ³æ³¢å½¢ã€‚}
\label{fig:system_overview}
\end{figure}
```

---

## 16. é—œéµæŠ€è¡“è²¢ç»

```mermaid
mindmap
  root((VITS<br/>æƒ…ç·’æ§åˆ¶))
    è²¢ç» 1
      Emotion Embedding
        é›¢æ•£æƒ…ç·’ ID
        n_emotions=4
        å‘é‡ç¶­åº¦ 256
    è²¢ç» 2
      Conditional LayerNorm
        å‹•æ…‹èª¿è£½ Î³, Î²
        æ‡‰ç”¨æ–¼æ‰€æœ‰å±¤
        æƒ…ç·’æ¢ä»¶æ³¨å…¥
    è²¢ç» 3
      Cross Conditional Attention
        å¤šé ­æ³¨æ„åŠ›
        æ–‡æœ¬-æƒ…ç·’äº¤äº’
        æ®˜å·®é€£æ¥
    è²¢ç» 4
      Duration Prediction
        SDP + DP æ··åˆ
        CLN æ¢ä»¶åŒ–
        æƒ…ç·’å½±éŸ¿éŸ»å¾‹
    è²¢ç» 5
      ç«¯åˆ°ç«¯è¨“ç·´
        å–®éšæ®µè¨“ç·´
        è¯åˆå„ªåŒ–
        ç„¡éœ€é è¨“ç·´
```

---

## åƒè€ƒæ–‡ç»å»ºè­°

### ç›¸é—œå·¥ä½œ

1. **VITS**: Kim et al., "Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech", ICML 2021

2. **Conditional LayerNorm**: Dumoulin et al., "A Learned Representation for Artistic Style", ICLR 2017

3. **Emotion TTS**:
   - Skerry-Ryan et al., "Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron", ICML 2018
   - Valle et al., "Flowtron: an Autoregressive Flow-based Generative Network for Text-to-Speech Synthesis", ICLR 2021

4. **eGeMAPS**: Eyben et al., "The Geneva Minimalistic Acoustic Parameter Set (GeMAPS) for Voice Research and Affective Computing", IEEE Trans. Affective Computing, 2016

---

## é™„éŒ„ï¼šç¬¦è™Ÿè¡¨

| ç¬¦è™Ÿ | èªªæ˜ | ç¶­åº¦ |
|------|------|------|
| $x$ | æ–‡æœ¬åºåˆ— | $[B, T_{text}]$ |
| $y$ | éŸ³é »æ³¢å½¢ | $[B, T_{audio}]$ |
| $\text{sid}$ | èªªè©±è€… ID | $[B]$ |
| $\text{eid}$ | æƒ…ç·’ ID | $[B]$ |
| $g$ | å…¨å±€æ¢ä»¶å‘é‡ | $[B, 256, 1]$ |
| $z$ | éš±è®Šé‡ | $[B, 192, T]$ |
| $m_p, \log s_p$ | å…ˆé©—å‡å€¼ã€æ–¹å·® | $[B, 192, T]$ |
| $m_q, \log s_q$ | å¾Œé©—å‡å€¼ã€æ–¹å·® | $[B, 192, T]$ |
| $d$ | æŒçºŒæ™‚é–“ | $[B, T_{text}]$ |
| $C$ | éš±è—ç¶­åº¦ | 192 |
| $C_{gin}$ | æ¢ä»¶ç¶­åº¦ | 256 |

---

**æœ¬æ¶æ§‹åœ–ä½¿ç”¨ Mermaid èªæ³•ç”Ÿæˆï¼Œå¯åœ¨æ”¯æ´ Mermaid çš„ Markdown ç·¨è¼¯å™¨ä¸­æ¸²æŸ“ï¼Œæˆ–ä½¿ç”¨å·¥å…·è½‰æ›ç‚º PDF/PNG æ ¼å¼ç”¨æ–¼è«–æ–‡ã€‚**
