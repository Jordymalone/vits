# Emotion-Controllable VITS - Flowchart æ¶æ§‹åœ–

> ğŸ“… ç”Ÿæˆæ—¥æœŸï¼š2026-01-09  
> ğŸ¯ ç”¨é€”ï¼šè«–æ–‡æ¶æ§‹åœ– (Mermaid Flowchart)

---

## 1. å®Œæ•´ç³»çµ±æ¶æ§‹ (System Overview)

```mermaid
flowchart TB
    subgraph Input["ğŸ“¥ è¼¸å…¥å±¤ Input Layer"]
        I1[Text/Phoneme<br/>æ–‡å­—åºåˆ—]
        I2[Speaker ID<br/>èªªè©±è€…]
        I3[Emotion ID<br/>æƒ…ç·’æ¨™ç±¤]
        I4[Reference Audio<br/>åƒè€ƒéŸ³é » å¯é¸]
    end

    subgraph Embedding["ğŸ”¤ åµŒå…¥å±¤ Embedding Layer"]
        E1[Speaker Embedding<br/>emb_g: 256-dim]
        E2[Emotion Embedding<br/>emb_e: 256-dim]
        E3["g = g_spk + g_emo<br/>å‘é‡èåˆ"]
    end

    subgraph eGeMAPS["ğŸµ eGeMAPS Pipeline å¯é¸"]
        G1[eGeMAPS Extractor<br/>F0/Energy/MFCC/Mel]
        G2[Feature Projection<br/>97 â†’ 88 dims]
        G3[eGeMAPS Encoder<br/>88 â†’ 192 dims]
    end

    subgraph TextEnc["ğŸ“ Text Encoder"]
        T1[Phoneme Embedding]
        T2[Transformer Ã— 6<br/>+ CLN]
        T3[CCA Module<br/>å¯é¸]
        T4["Prior: m_p, logs_p"]
    end

    subgraph Duration["â±ï¸ Duration Predictor"]
        D1[SDP: Stochastic]
        D2[DP: Deterministic]
        D3["Mix: 0.1Ã—SDP + 0.9Ã—DP"]
    end

    subgraph Flow["ğŸŒŠ Normalizing Flow"]
        F1[Residual Coupling Ã— 4]
    end

    subgraph Decoder["ğŸ”Š HiFi-GAN Decoder"]
        DEC1[Upsampling Ã— 4]
        DEC2[MRF ResBlocks]
        DEC3[Waveform Output]
    end

    I1 --> T1
    I2 --> E1
    I3 --> E2
    I4 -.-> G1

    E1 --> E3
    E2 --> E3

    G1 --> G2 --> G3

    T1 --> T2
    E3 --> T2
    T2 --> T3
    G3 -.-> T3
    T3 --> T4

    T4 --> D1
    T4 --> D2
    E3 --> D1
    E3 --> D2
    D1 --> D3
    D2 --> D3

    D3 --> F1
    E3 --> F1

    F1 --> DEC1
    E3 --> DEC1
    DEC1 --> DEC2
    DEC2 --> DEC3

    style Input fill:#e1f5ff
    style Embedding fill:#fff4e1
    style eGeMAPS fill:#ffe1f5
    style TextEnc fill:#e1ffe1
    style Duration fill:#f5e1ff
    style Flow fill:#e1e1ff
    style Decoder fill:#ffffe1
```

---

## 2. è¨“ç·´æµç¨‹ (Training Pipeline)

```mermaid
flowchart TB
    subgraph DataLoad["ğŸ“‚ æ•¸æ“šè¼‰å…¥"]
        DL1[(Filelist<br/>audio|sid|lang|text|eid)]
        DL2[TextAudioSpeakerLoader]
        DL3[Batch Collate]
    end

    subgraph Forward["âš¡ å‰å‘å‚³æ’­"]
        FW1[Text Encoder<br/>+ CLN + CCA]
        FW2[Posterior Encoder<br/>Mel â†’ z_q]
        FW3[Flow: z_q â†’ z_p]
        FW4[MAS Alignment]
        FW5[Duration Prediction]
        FW6[HiFi-GAN Decode]
    end

    subgraph Loss["ğŸ“‰ æå¤±è¨ˆç®—"]
        L1["L_mel = ||Mel_real - Mel_fake||â‚"]
        L2["L_kl = KL(z_q || z_p)"]
        L3["L_dur = MSE(log_dur)"]
        L4["L_adv = GAN Loss"]
        L5["L_fm = Feature Matching"]
        L6["L_total = L_melÃ—45 + L_kl + L_dur + L_adv + L_fm"]
    end

    subgraph Optim["ğŸ”„ å„ªåŒ–"]
        O1[Generator Optimizer<br/>AdamW lr=2e-4]
        O2[Discriminator Optimizer<br/>AdamW lr=2e-4]
    end

    DL1 --> DL2 --> DL3
    DL3 --> FW1
    FW1 --> FW4
    FW2 --> FW3
    FW3 --> FW4
    FW4 --> FW5
    FW5 --> FW6

    FW6 --> L1
    FW3 --> L2
    FW5 --> L3
    FW6 --> L4
    FW6 --> L5
    L1 & L2 & L3 & L4 & L5 --> L6

    L6 --> O1
    L4 --> O2
    O1 & O2 -.->|è¿­ä»£| FW1

    style DataLoad fill:#e1f5ff
    style Forward fill:#e1ffe1
    style Loss fill:#ffe1e1
    style Optim fill:#f5e1ff
```

---

## 3. æ¨è«–æµç¨‹ (Inference Pipeline)

```mermaid
flowchart TB
    subgraph Input["ğŸ‘¤ ç”¨æˆ¶è¼¸å…¥"]
        IN1[æ–‡æœ¬ Text]
        IN2[Speaker ID]
        IN3[Emotion ID<br/>æˆ– Reference Audio]
    end

    subgraph Step1["Step 1: åµŒå…¥"]
        S1A["g_spk = Embedding(sid)"]
        S1B["g_emo = Embedding(eid)"]
        S1C["g = g_spk + g_emo"]
    end

    subgraph Step2["Step 2: eGeMAPS å¯é¸"]
        S2A[eGeMAPS Extract]
        S2B[eGeMAPS Encode]
    end

    subgraph Step3["Step 3: æ–‡æœ¬ç·¨ç¢¼"]
        S3A[Text Encoder<br/>with CLN]
        S3B[CCA Attention<br/>å¯é¸]
        S3C["Output: m_p, logs_p"]
    end

    subgraph Step4["Step 4: æ™‚é•·é æ¸¬"]
        S4A["log_dur = 0.1Ã—SDP + 0.9Ã—DP"]
        S4B["dur = ceil(exp(log_dur) Ã— length_scale)"]
    end

    subgraph Step5["Step 5: å°é½Šæ“´å±•"]
        S5A[Generate Path]
        S5B["Expand m_p, logs_p to T_audio"]
    end

    subgraph Step6["Step 6: æ¡æ¨£"]
        S6A["z_p = m_p + Îµ Ã— exp(logs_p) Ã— noise_scale"]
    end

    subgraph Step7["Step 7: Flow åå‘"]
        S7A["z = Flowâ»Â¹(z_p, g)"]
    end

    subgraph Step8["Step 8: è§£ç¢¼"]
        S8A[HiFi-GAN Decoder]
        S8B[ğŸ”Š Waveform Output]
    end

    IN1 --> S3A
    IN2 --> S1A
    IN3 --> S1B
    IN3 -.-> S2A

    S1A --> S1C
    S1B --> S1C

    S2A --> S2B
    S2B -.-> S3B

    S1C --> S3A
    S3A --> S3B
    S3B --> S3C

    S3C --> S4A
    S1C --> S4A
    S4A --> S4B

    S4B --> S5A
    S3C --> S5A
    S5A --> S5B

    S5B --> S6A

    S6A --> S7A
    S1C --> S7A

    S7A --> S8A
    S1C --> S8A
    S8A --> S8B

    style Input fill:#e1f5ff
    style Step1 fill:#fff4e1
    style Step2 fill:#ffe1f5
    style Step3 fill:#e1ffe1
    style Step4 fill:#f5e1ff
    style Step5 fill:#e1e1ff
    style Step6 fill:#ffffe1
    style Step7 fill:#e1ffff
    style Step8 fill:#ffe1e1
```

---

## 4. Conditional Layer Normalization (CLN) æ©Ÿåˆ¶

```mermaid
flowchart LR
    subgraph Input["è¼¸å…¥"]
        I1["x: ç‰¹å¾µ<br/>[B, C, T]"]
        I2["g: æ¢ä»¶<br/>[B, 256, 1]"]
    end

    subgraph Norm["LayerNorm"]
        N1["Î¼ = mean(x)"]
        N2["ÏƒÂ² = var(x)"]
        N3["x_norm = (x - Î¼) / âˆš(ÏƒÂ² + Îµ)"]
    end

    subgraph Cond["æ¢ä»¶ç”Ÿæˆ"]
        C1["Conv1d(g)<br/>256 â†’ 2Ã—C"]
        C2["Split â†’ Î³_c, Î²_c"]
    end

    subgraph Modulate["èª¿è£½"]
        M1["Scale: x_norm Ã— (1 + Î³_c)"]
        M2["Shift: + Î²_c"]
    end

    subgraph Output["è¼¸å‡º"]
        O1["y: èª¿è£½å¾Œç‰¹å¾µ<br/>[B, C, T]"]
    end

    I1 --> N1 & N2
    N1 & N2 --> N3

    I2 --> C1
    C1 --> C2

    N3 --> M1
    C2 --> M1
    M1 --> M2
    C2 --> M2

    M2 --> O1

    style Input fill:#e1f5ff
    style Norm fill:#fff4e1
    style Cond fill:#ffe1f5
    style Modulate fill:#e1ffe1
    style Output fill:#ffffe1
```

**æ•¸å­¸å…¬å¼ï¼š**
$$\text{CLN}(x, g) = (1 + \gamma_c) \odot \text{LN}(x) + \beta_c$$
$$[\gamma_c, \beta_c] = \text{Conv1D}(g)$$

---

## 5. Cross-Conditional Attention (CCA) æ©Ÿåˆ¶

```mermaid
flowchart TB
    subgraph Input["è¼¸å…¥"]
        I1["x_text: æ–‡æœ¬ç‰¹å¾µ<br/>[B, 192, T_text]"]
        I2["emo_feat: æƒ…ç·’ç‰¹å¾µ<br/>[B, 192, T_emo]"]
    end

    subgraph Projection["æŠ•å½±å±¤"]
        P1["Q = Conv_q(x_text)<br/>Query from Text"]
        P2["K = Conv_k(emo_feat)<br/>Key from Emotion"]
        P3["V = Conv_v(emo_feat)<br/>Value from Emotion"]
    end

    subgraph Attention["Multi-Head Attention"]
        A1["Reshape to<br/>[B, n_heads, T, d_k]"]
        A2["scores = Q Ã— K^T / âˆšd_k"]
        A3["attn = Softmax(scores)"]
        A4["out = attn Ã— V"]
    end

    subgraph Output["è¼¸å‡º"]
        O1["Conv_o: è¼¸å‡ºæŠ•å½±"]
        O2["Residual: x_text + out"]
        O3["LayerNorm"]
    end

    I1 --> P1
    I2 --> P2 & P3

    P1 --> A1
    P2 --> A1
    P3 --> A1

    A1 --> A2
    A2 --> A3
    A3 --> A4

    A4 --> O1
    O1 --> O2
    I1 --> O2
    O2 --> O3

    style Input fill:#e1f5ff
    style Projection fill:#fff4e1
    style Attention fill:#ffe1f5
    style Output fill:#e1ffe1
```

**æ•¸å­¸å…¬å¼ï¼š**
$$\text{CCA}(x, c) = \text{LN}(x + \text{MultiHead}(Q, K, V))$$
$$Q = W_q \cdot x, \quad K = W_k \cdot c, \quad V = W_v \cdot c$$

---

## 6. eGeMAPS ç‰¹å¾µæå–æµç¨‹

```mermaid
flowchart TB
    subgraph Input["ğŸ“¥ è¼¸å…¥"]
        I1["Reference Audio<br/>[B, T_wav]"]
    end

    subgraph Extract["ğŸµ ç‰¹å¾µæå–"]
        E1["Mel-Spectrogram<br/>80 dims"]
        E2["MFCC<br/>13 dims"]
        E3["F0 åŸºé »<br/>1 dim"]
        E4["Energy èƒ½é‡<br/>1 dim"]
        E5["Spectral Flux<br/>1 dim"]
        E6["Zero Crossing Rate<br/>1 dim"]
    end

    subgraph Concat["ğŸ”— æ‹¼æ¥"]
        C1["Total: 97 dims<br/>[B, 97, T_frames]"]
    end

    subgraph Project["ğŸ“Š æŠ•å½±"]
        P1["MLP: 97 â†’ 256 â†’ 88<br/>[B, 88, T_frames]"]
    end

    subgraph Encode["ğŸ”§ ç·¨ç¢¼"]
        EN1["Pre Conv1d: 88 â†’ 192"]
        EN2["Conv Block Ã— 3<br/>+ LayerNorm + ReLU<br/>+ Residual"]
        EN3["Output: 192 dims<br/>[B, 192, T_frames]"]
    end

    subgraph Usage["ğŸ¯ ä½¿ç”¨"]
        U1["â†’ CCA Module<br/>ä½œç‚º Key/Value"]
    end

    I1 --> E1 & E2 & E3 & E4 & E5 & E6
    E1 & E2 & E3 & E4 & E5 & E6 --> C1
    C1 --> P1
    P1 --> EN1
    EN1 --> EN2
    EN2 --> EN3
    EN3 --> U1

    style Input fill:#e1f5ff
    style Extract fill:#fff4e1
    style Concat fill:#ffe1f5
    style Project fill:#e1ffe1
    style Encode fill:#f5e1ff
    style Usage fill:#ffffe1
```

---

## 7. Duration Prediction æ©Ÿåˆ¶

```mermaid
flowchart TB
    subgraph Input["ğŸ“¥ è¼¸å…¥"]
        I1["x: Text Encoding<br/>[B, 192, T_text]"]
        I2["g: Global Condition<br/>[B, 256, 1]"]
    end

    subgraph SDP["ğŸ² Stochastic Duration Predictor"]
        S1["Transformer Layer<br/>+ CLN"]
        S2["DDSConv Processing"]
        S3["Flow Coupling Ã— 4"]
        S4["log_dur_sdp"]
    end

    subgraph DP["ğŸ“ Deterministic Duration Predictor"]
        D1["Conv Layer 1<br/>+ CLN + ReLU"]
        D2["Conv Layer 2<br/>+ CLN + ReLU"]
        D3["Projection â†’ 1"]
        D4["log_dur_dp"]
    end

    subgraph Mix["ğŸ”€ æ··åˆç­–ç•¥"]
        M1["log_dur = 0.1 Ã— SDP + 0.9 Ã— DP"]
        M2["dur = ceil(exp(log_dur) Ã— length_scale)"]
    end

    subgraph Align["ğŸ¯ å°é½Š"]
        A1["Generate Monotonic Path"]
        A2["Expand Features to T_audio"]
    end

    I1 --> S1
    I2 --> S1
    S1 --> S2 --> S3 --> S4

    I1 --> D1
    I2 --> D1
    D1 --> D2 --> D3 --> D4

    S4 --> M1
    D4 --> M1
    M1 --> M2
    M2 --> A1
    A1 --> A2

    style Input fill:#e1f5ff
    style SDP fill:#ffe1f5
    style DP fill:#fff4e1
    style Mix fill:#e1ffe1
    style Align fill:#ffffe1
```

---

## 8. æƒ…ç·’æ§åˆ¶æ¨¡å¼å°æ¯”

```mermaid
flowchart TB
    subgraph ModeA["æ¨¡å¼ A: Emotion Embedding"]
        A1["Emotion ID<br/>(0=neutral, 1=happy, 2=sad, 3=angry)"]
        A2["Embedding Table<br/>[n_emotions, 256]"]
        A3["g_emo â†’ CLN"]
        A1 --> A2 --> A3
    end

    subgraph ModeB["æ¨¡å¼ B: eGeMAPS + CCA"]
        B1["Reference Audio"]
        B2["eGeMAPS Features<br/>[B, 88, T]"]
        B3["eGeMAPS Encoder<br/>[B, 192, T]"]
        B4["CCA with Text"]
        B1 --> B2 --> B3 --> B4
    end

    subgraph ModeC["æ¨¡å¼ C: æ··åˆæ¨¡å¼"]
        C1["Emotion ID â†’ CLN<br/>ç²—ç²’åº¦æ§åˆ¶"]
        C2["Reference Audio â†’ CCA<br/>ç´°ç²’åº¦æ§åˆ¶"]
        C3["é›™é‡æƒ…ç·’æ³¨å…¥"]
        C1 --> C3
        C2 --> C3
    end

    subgraph Effect["ğŸ’« æ•ˆæœ"]
        E1["Duration è®ŠåŒ–<br/>Happy: å¿« / Sad: æ…¢"]
        E2["F0 Pitch è®ŠåŒ–<br/>Happy: é«˜ / Sad: ä½"]
        E3["Energy è®ŠåŒ–<br/>Angry: é«˜ / Sad: ä½"]
    end

    ModeA --> Effect
    ModeB --> Effect
    ModeC --> Effect

    style ModeA fill:#e1f5ff
    style ModeB fill:#ffe1f5
    style ModeC fill:#e1ffe1
    style Effect fill:#ffffe1
```

---

## 9. æ•´é«”æ¶æ§‹åœ– (ç°¡åŒ–ç‰ˆ)

```mermaid
flowchart LR
    subgraph In["Input"]
        Text
        SpeakerID
        EmotionID
        RefAudio
    end

    subgraph Enc["Encoding"]
        TextEnc["Text Encoder<br/>+ CLN + CCA"]
        EmoEnc["eGeMAPS Encoder"]
    end

    subgraph Pred["Prediction"]
        DurPred["Duration<br/>Predictor"]
        Flow["Normalizing<br/>Flow"]
    end

    subgraph Dec["Decoding"]
        HiFiGAN["HiFi-GAN<br/>Decoder"]
    end

    subgraph Out["Output"]
        Waveform["ğŸ”Š Audio"]
    end

    Text --> TextEnc
    SpeakerID --> TextEnc
    EmotionID --> TextEnc
    RefAudio -.-> EmoEnc
    EmoEnc -.-> TextEnc

    TextEnc --> DurPred
    TextEnc --> Flow
    DurPred --> Flow

    Flow --> HiFiGAN
    HiFiGAN --> Waveform

    style In fill:#e1f5ff
    style Enc fill:#e1ffe1
    style Pred fill:#fff4e1
    style Dec fill:#ffe1f5
    style Out fill:#ffffe1
```

---

## 10. è«–æ–‡ç”¨æ¶æ§‹åœ– (Paper-Ready)

```mermaid
flowchart TB
    subgraph Training["Training Phase"]
        direction TB
        T_Text["Text x"] --> T_TextEnc["Text Encoder<br/>+ CLN"]
        T_Mel["Mel y"] --> T_PosEnc["Posterior<br/>Encoder"]
        T_Spk["Speaker ID"] --> T_Emb["Embeddings"]
        T_Emo["Emotion ID"] --> T_Emb
        T_Ref["Ref Audio"] -.-> T_eGeMAPS["eGeMAPS"]
        
        T_eGeMAPS -.-> T_CCA["CCA"]
        T_TextEnc --> T_CCA
        T_CCA --> T_Prior["Prior<br/>m_p, logs_p"]
        
        T_PosEnc --> T_Flow["Flow"]
        T_Prior --> T_MAS["MAS"]
        T_Flow --> T_MAS
        
        T_MAS --> T_DurPred["Duration<br/>Predictor"]
        T_Flow --> T_Dec["Decoder"]
        T_Dec --> T_Out["Å·"]
        
        T_Emb --> T_TextEnc
        T_Emb --> T_PosEnc
        T_Emb --> T_Flow
        T_Emb --> T_Dec
    end

    subgraph Inference["Inference Phase"]
        direction TB
        I_Text["Text x"] --> I_TextEnc["Text Encoder<br/>+ CLN"]
        I_Spk["Speaker ID"] --> I_Emb["Embeddings"]
        I_Emo["Emotion/Ref"] --> I_Emb
        
        I_Emb --> I_TextEnc
        I_TextEnc --> I_DurPred["Duration<br/>Predictor"]
        I_DurPred --> I_Expand["Expand"]
        I_TextEnc --> I_Expand
        I_Expand --> I_Sample["Sample z_p"]
        I_Sample --> I_Flow["Flowâ»Â¹"]
        I_Flow --> I_Dec["Decoder"]
        I_Dec --> I_Out["Å·"]
        
        I_Emb --> I_Flow
        I_Emb --> I_Dec
    end

    style Training fill:#e1f5ff
    style Inference fill:#e1ffe1
```

---

*Generated: 2026-01-09*
